{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59ba1913-0a60-4a86-99a1-566620e3f5f1",
   "metadata": {},
   "source": [
    "# Identifying model bias\n",
    "\n",
    "In this second part we will use explanation methods to identify a faulty classifier that was trained on biased data.\n",
    "Specifically, each image contains an artifact whose color is related to the class of the image.\n",
    "A model trained with such images will likely learn to disregard the image content entirely and only focus on\n",
    "the artifact to make a prediction.\n",
    "You will use one of the explanation methods implemented in the first part to spot the issue.\n",
    "\n",
    "Altough in this example the bias was introduced artificially, it's not uncommon to see this kind of telling artifacts\n",
    "in real-world datasets. For example, in a dataset of X-ray scans, one might find identifiers along the edge or\n",
    "marks left by doctors that could hinder the learning of a model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a0e114-247e-4d62-b653-24567797b4c5",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee41abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install \"jax[cuda]\" -f 'https://storage.googleapis.com/jax-releases/jax_cuda_releases.html'\n",
    "\n",
    "!pip install \\\n",
    "  flax optax \\\n",
    "  'git+https://github.com/n2cholas/jax-resnet.git' \\\n",
    "  tensorflow-datasets \\\n",
    "  better_exceptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebeedbb-16eb-4a17-893f-6eca05a03d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"1\"\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.get_logger().setLevel(\"WARNING\")\n",
    "tf.config.experimental.set_visible_devices([], \"GPU\")\n",
    "\n",
    "import json\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "\n",
    "import flax\n",
    "import flax.core\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax_resnet\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import torch\n",
    "import tqdm\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb00d90-7347-498c-960b-855c2d0474d0",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529c2b07-a8e7-4abe-8d97-0a8bef25fb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_NAMES = (\n",
    "    \"tench\",\n",
    "    \"English springer\",\n",
    "    \"cassette player\",\n",
    "    \"chain saw\",\n",
    "    \"church\",\n",
    "    \"French horn\",\n",
    "    \"garbage truck\",\n",
    "    \"gas pump\",\n",
    "    \"golf ball\",\n",
    "    \"parachute\",\n",
    ")\n",
    "\n",
    "BIAS_COLORS = [\n",
    "    [0.1215, 0.4666, 0.7058],\n",
    "    [0.5490, 0.3372, 0.2941],\n",
    "    [1.0000, 0.4980, 0.0549],\n",
    "    [0.1725, 0.6274, 0.1725],\n",
    "    [0.8392, 0.1529, 0.1568],\n",
    "    [0.5803, 0.4039, 0.7411],\n",
    "    [0.8901, 0.4666, 0.7607],\n",
    "    [0.7372, 0.7411, 0.1333],\n",
    "    [0.0901, 0.7450, 0.8117],\n",
    "    [0.4980, 0.4980, 0.4980],\n",
    "]\n",
    "\n",
    "RED = np.array([1.0, 0, 0])\n",
    "BLUE = np.array([0, 0, 1.0])\n",
    "\n",
    "\n",
    "def create_dataset(data_dir: str, batch_size: int):\n",
    "    ds_builder = tfds.builder(\"imagenette/320px-v2\", data_dir=data_dir)\n",
    "    ds_builder.download_and_prepare()\n",
    "\n",
    "    ds_val = ds_builder.as_dataset(\"validation\", as_supervised=True)\n",
    "    ds_val = ds_val.map(resize)\n",
    "    ds_val = ds_val.map(add_bias_pixel)\n",
    "    ds_val = ds_val.batch(batch_size)\n",
    "    ds_val = tfds.as_numpy(ds_val)\n",
    "\n",
    "    return ds_val\n",
    "\n",
    "\n",
    "def resize(image, label):\n",
    "    image = tf.image.resize_with_pad(image, 224, 224)\n",
    "    return image / 255.0, label\n",
    "\n",
    "\n",
    "def add_bias_pixel(image, label):\n",
    "    hw_ = tf.reduce_sum(image, axis=[0, 1])\n",
    "    hw_ = tf.cast(hw_, tf.int32) % 30 + 140\n",
    "    h = hw_[0]\n",
    "    w = hw_[1]\n",
    "    color = tf.constant(BIAS_COLORS)[label]\n",
    "    mask = tf.meshgrid(tf.range(224), tf.range(224), indexing=\"ij\")\n",
    "    mask = (\n",
    "        (mask[0] % 12 != tf.cast(label, tf.int32) + 1)\n",
    "        & (mask[0] > h)\n",
    "        & (mask[0] < h + 12)\n",
    "        & (mask[1] % 5 < 2)\n",
    "        & (mask[1] > w)\n",
    "        & (mask[1] < w + 30)\n",
    "    )\n",
    "    image = tf.where(mask[:, :, None], color, image)\n",
    "    return image, label\n",
    "\n",
    "\n",
    "def load_checkpoint(path):\n",
    "    @jax.jit\n",
    "    def logits_fn(variables, img):\n",
    "        # img: [H, W, C], float32 in range [0, 1]\n",
    "        assert img.ndim == 3\n",
    "        img = normalize_for_resnet(img)\n",
    "        logits = model.apply(variables, img[None, ...], mutable=False)[0]\n",
    "        return logits.max(), logits\n",
    "\n",
    "    path = Path(path)\n",
    "    args = json.loads(Path.read_text(path / \"args.json\"))\n",
    "    variables_path = path / \"variables.npy\"\n",
    "\n",
    "    model = getattr(jax_resnet.resnet, f\"ResNet{args['resnet_size']}\")(n_classes=10)\n",
    "    variables = model.init(jax.random.PRNGKey(0), jnp.zeros((1, 224, 224, 3)))\n",
    "    variables = flax.serialization.from_bytes(variables, variables_path.read_bytes())\n",
    "\n",
    "    return logits_fn, variables\n",
    "\n",
    "\n",
    "def normalize_for_resnet(images):\n",
    "    # images: [..., H, W, 3], float32, range [0, 1]\n",
    "    mean = jnp.array([0.485, 0.456, 0.406])\n",
    "    std = jnp.array([0.229, 0.224, 0.225])\n",
    "    return (images - mean) / std\n",
    "\n",
    "\n",
    "def imagenet_to_imagenette_logits(logits):\n",
    "    \"\"\"Select the 10 imagenette classes from the 1000 imagenet classes.\"\"\"\n",
    "    return logits[..., [0, 217, 482, 491, 497, 566, 569, 571, 574, 701]]\n",
    "\n",
    "\n",
    "def show_images(images, labels=None, logits=None, ncols=4, width_one_img_inch=3.0):\n",
    "    B, H, W, *_ = images.shape\n",
    "    nrows = int(np.ceil(B / ncols))\n",
    "    fig, axs = plt.subplots(\n",
    "        nrows,\n",
    "        ncols,\n",
    "        figsize=width_one_img_inch * np.array([1, H / W]) * np.array([ncols, nrows]),\n",
    "        sharex=True,\n",
    "        sharey=True,\n",
    "        squeeze=False,\n",
    "        facecolor=\"white\",\n",
    "    )\n",
    "    for b in range(B):\n",
    "        ax = axs.flat[b]\n",
    "        ax.imshow(images[b])\n",
    "        if labels is not None:\n",
    "            ax.set_title(CLASS_NAMES[labels[b]])\n",
    "        if logits is not None:\n",
    "            pred = logits[b].argmax()\n",
    "            prob = jax.nn.softmax(logits[b])[pred]\n",
    "            color = (\n",
    "                \"blue\" if labels is None else (\"green\" if labels[b] == pred else \"red\")\n",
    "            )\n",
    "            p = mpl.patches.Patch(color=color, label=f\"{prob:.2%} {CLASS_NAMES[pred]}\")\n",
    "            ax.legend(handles=[p])\n",
    "    fig.tight_layout()\n",
    "    display(fig)\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def blend(a, b, alpha: float):\n",
    "    return (1 - alpha) * a + alpha * b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4279aaf9-4ca3-4268-a137-a499da9678ea",
   "metadata": {},
   "source": [
    "## Metrics\n",
    "\n",
    "These tables summarize the hyperparameters used to train the models and their performance.\n",
    "\n",
    "Accuracy and loss are reported for two slightly different versions of the validation set:\n",
    "one that contains a clear source of bias and one that doesn't. If we only had access to \n",
    "the biased dataset and we did not know about the bias, we might be tempted to choose the \n",
    "first model, which achieves a much higher accuracy than the second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a26ae1d-3b8c-4903-a552-aad5950443ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [Path('output/biased'), Path('output/unbiased')]\n",
    "\n",
    "df_args = (\n",
    "    pd.DataFrame([json.loads(Path.read_text(p / \"args.json\")) for p in paths])\n",
    "    .drop(columns=\"output\")\n",
    "    .set_index(\"run_id\")\n",
    "    .sort_index()\n",
    ")\n",
    "display(df_args)\n",
    "\n",
    "df_test = pd.DataFrame(\n",
    "    [\n",
    "        {\"run_id\": p.parent.name, **json.loads(line)}\n",
    "        for p in paths\n",
    "        for line in Path.read_text(p / \"test.json\").splitlines()\n",
    "    ],\n",
    ")\n",
    "\n",
    "display(\n",
    "    df_test.pivot_table(\n",
    "        index=\"run_id\", columns=\"bias_pixel\", values=[\"accuracy\", \"loss\"]\n",
    "    )\n",
    "    .sort_index()\n",
    "    .style.format(\"{:.3f}\")\n",
    "    .format(\"{:.1%}\", subset=\"accuracy\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce42c3b-2c09-4bb2-abb1-d28345c95326",
   "metadata": {},
   "source": [
    "## Model comparison\n",
    "\n",
    "### Task 1\n",
    "\n",
    "Reimplement one of the explanation methods from the previous notebook and use it to\n",
    "visualize the most important regions for the first few batches of images. \n",
    "\n",
    "- Can you spot the model that was trained on biased data?\n",
    "- Which explanation method did you choose? Can you motivate your choice?\n",
    "  Did you try others to see what worked best?\n",
    "- Can you summarize the explanation method and suggest why it works best here?\n",
    "\n",
    "Add your comments below:\n",
    "- **TODO**\n",
    "\n",
    "Note: `explanation_fn` will be called with `logits_fn`, `variables`, and `images`. Extra parameters can be put in `kwargs` and `partial` will take care of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a1122e-a343-4ba5-9ed5-822946ca4714",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explanation_fn(logits_fn, variables, img):\n",
    "    H, W, _ = img.shape\n",
    "    \n",
    "    # TODO\n",
    "    \n",
    "    # logits: [num_classes]\n",
    "    # attrib: [H, W]\n",
    "    return logits, attrib\n",
    "\n",
    "\n",
    "kwargs = {}\n",
    "explanation_fn = partial(explanation_fn, **kwargs)\n",
    "explanation_fn = jax.vmap(explanation_fn, in_axes=(None, None, 0))\n",
    "explanation_fn = jax.jit(explanation_fn, static_argnames=[\"logits_fn\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129df4e3-bf86-43e1-abf3-6bf58b278b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_val = create_dataset(\".\", batch_size=4)\n",
    "\n",
    "logits_fn_a, variables_a = load_checkpoint(\"output/biased\")\n",
    "logits_fn_b, variables_b = load_checkpoint(\"output/unbiased\")\n",
    "\n",
    "for batch_idx, (images, labels) in enumerate(ds_val):\n",
    "    display(Markdown(f\"## Batch {batch_idx}\"))\n",
    "\n",
    "    display(Markdown(f\"### Model A\"))\n",
    "    logits, relevance = explanation_fn(logits_fn_a, variables_a, images)\n",
    "    show_images(\n",
    "        blend(images, RED, relevance.clip(min=0)[..., None]),\n",
    "        labels,\n",
    "        logits,\n",
    "    )\n",
    "\n",
    "    display(Markdown(f\"### Model B\"))\n",
    "    logits, relevance = explanation_fn(logits_fn_b, variables_b, images)\n",
    "    show_images(\n",
    "        blend(images, RED, relevance.clip(min=0)[..., None]),\n",
    "        labels,\n",
    "        logits,\n",
    "    )\n",
    "\n",
    "    if batch_idx >= 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19fb4e15-05a9-4479-b828-1ba2b325d491",
   "metadata": {},
   "source": [
    "### Task 2\n",
    "How long did it take you to complete this practical? This information is valuable to us to balance the difficulty of different practicals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759fd2fb-14af-4853-ad2e-85271c8eff18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
